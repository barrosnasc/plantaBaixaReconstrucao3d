\chapter{Referencial Teórico}\label{cp:refteory}
\ABNTEXchapterfont
% Justificativa das tecnologias, comparação 
%Este capítulo é um componente importante para esse estudo, pois fornece uma base  explorando as principais teorias, conceitos e definições existentes sobre as áreas de conhecimento que motivaram a elaboração deste projeto de pesquisa e que guiarão a execução do percurso metodológico.

%Escreva sobre o referencial teórico do seu trabalho

% Qual é o tipo de problema
% Utilizando o artigo do 3DPlanNet

Como já citado, o desenho arquitetônico contém vários tipos de objetos: paredes, portas, janelas, quartos, nomes de cômodos, móveis e suas dimensões, entre outros. Cada autor opta por dar ênfase a determinados desses aspectos. Seguindo a abordagem de \citeonline{kratochvila2024multi} e \citeonline{lv2021residential}, a implementação é dividida em duas etapas: reconhecimento e reconstrução.
Na etapa de reconhecimento ocorre o processamento de imagem, gerando um modelo intermediário, e na reconstrução são realizados o pós-processamento e a criação do modelo 3D, com pelo menos os objetos de parede, porta e janela.

No reconhecimento há a detecção de paredes, portas e janelas, sendo criada uma rede de vértices e arestas das paredes \cite{3dplanet2021}. Dependendo do autor, pode haver detecção dos outros tipos de objetos presentes na planta.
Na reconstrução é feito o pós-processamento para reduzir erros e, em seguida, é criado o modelo 3D usando tamanhos padrão para os objetos, como altura e largura da parede. Caso a técnica permita detectar outros elementos na etapa anterior, eles são adicionados ao modelo 3D.



\section{Trabalhos Relacionados}

\citeonline{kratochvila2024multi} desenvolveram dois algoritmos de segmentação, denominados CAB1 e CAB2, que utilizam um mecanismo de atenção \textit{(Attention Mechanism)} composto por CAM e SAM. Na etapa de reconstrução, cada categoria de pixel segmentada foi vetorizada, para, então gerar o modelo 3D. Foram utilizadas 560 imagens escolhidas do \textit{dataset} CubiCasa5K.
 A \autoref{fig:kratochvila2024} mostra a visão geral apresentada pelos autores.

\citeonline{lv2021residential} realizaram a detecção de áreas de interesse, textos e símbolos (móveis, pias) utilizando YOLOv4 \cite{bochkovskiy2020yolov4}.
O método calcula a escala do desenho, pixel por milímetro, enquanto outros, como o de \cite{3dplanet2021}, utilizaram um tamanho padrão.
Foi empregado um \textit{dataset} próprio com 7.000 imagens de residências chinesas.
A \autoref{fig:lv2021} mostra a visão geral apresentada pelos autores.

\citeonline{barreiro2023automatic} destacam a importância de focar apenas em paredes, portas e janelas, pois as anotações referentes ao tipo de cômodo são específicas de cada \textit{dataset} e dificultam a criação de uma técnica generalizada. 
A sequência de etapas proposta envolve a detecção de símbolos para identificar portas e janelas, seguida da segmentação de paredes utilizando arquitetura \textit{FPN} com o \textit{backbone} \textit{ResNet}, semelhante à de \cite{lv2021residential}. 
A \autoref{fig:barreiro2023automatic} mostra a visão geral apresentada pelos autores.

\citeonline{3dplanet2021}, citados por \citeonline{kratochvila2024multi}, utilizaram o algoritmo de \cite{ijgi9020065} para detectar o centro das paredes. 
O método emprega a \textit{API} do \textit{Tensorflow} para a detecção de objetos: tipo de cômodo, portas e janelas. 
Foram 30 imagens escolhidas aleatoriamente, provenientes do \textit{dataset} de \citeonline{ijgi9020065}, que contém 110.000 imagens.
A \autoref{fig:3dplanet2021} mostra a visão geral apresentada pelos autores.

\begin{figure}[H]
\centering
\caption{Arquiteturas de Kratochvila et al. (2024) e Lv et al. (2021)}
\begin{subfigure}{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{imagens/kratochvila2024multi_figure4.png}
  \caption{Kratochvila et al. (2024)}
  \label{fig:kratochvila2024}
\end{subfigure}
\hfill
\begin{subfigure}{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{imagens/Lv_2021_figure2.png}
  \caption{Lv et al. (2021)}
  \label{fig:lv2021}
\end{subfigure}
\legend{Fonte: (a) \cite{kratochvila2024multi}, p. 5; (b) \cite{lv2021residential}, p. 16719.}
\label{fig:arquiteturas1}
\end{figure}

\begin{figure}[H]
\centering
\caption{Arquiteturas de Barreiro et al. (2023) e Park e Kim (2021)}
\begin{subfigure}{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{imagens/barreiro2023automatic_figure1.png}
  \caption{Da direita para a esquerda, planta baixa, máscara segmentada, resultados vetorizados e modelo 3D}
  \label{fig:barreiro2023automatic}
\end{subfigure}
\hfill
\begin{subfigure}{0.47\textwidth}
  \centering
  \includegraphics[width=\linewidth]{imagens/3dplanet2021_figure1.png}
  \caption{Lv et al. (2021)}
  \label{fig:3dplanet2021}
\end{subfigure}
\legend{Fonte: (a) \cite{barreiro2023automatic}, p. 3; (b) \cite{3dplanet2021}, p. 3.}
\label{fig:arquiteturas2}
\end{figure}


% colocar a figura do artigo

% O processamento da imagem gera alguns problemas sendo que antes foram solucionados por algoritmos heurísticos, mas atualmente as soluções usam técnicas de aprendizagem profunda \iffalse referênciar? \fi e essa mudança mostrou uma melhora na acurácia na detecção dos objetos \cite{3dplanet2021}.

% Um dos problemas que isso gera é a necessidade da criação de datasets devidamente anotados para treinar os modelos de aprendizagem profundas.

% Utilizar o resumo/conclusão de cada artigo, e discutir sobre os métodos e os achados e comentar sobre os artigos mostrando que ainda há algo a ser feito 

% Como as pessoas estão resolvendo os problemas
% sugestão de tabelinha de como comparar as diferentes soluções ajuda consideravelmente no entendimento do trabalho

\section{Considerações Finais}
Os trabalhos analisados utilizam técnicas de processamento de imagem e reconstrução 3D, mas a indisponibilidade de código-fonte dificulta sua reprodução.
